{"PubmedArticle": [{"MedlineCitation": {"OtherID": [], "SpaceFlightMission": [], "KeywordList": [], "CitationSubset": ["IM"], "InvestigatorList": [], "OtherAbstract": [], "GeneralNote": [], "PMID": "36068261", "DateCompleted": {"Year": "2022", "Month": "09", "Day": "08"}, "DateRevised": {"Year": "2022", "Month": "11", "Day": "09"}, "Article": {"Language": ["eng"], "ArticleDate": [{"Year": "2022", "Month": "09", "Day": "06"}], "ELocationID": ["15113", "10.1038/s41598-022-19281-7"], "Journal": {"ISSN": "2045-2322", "JournalIssue": {"Volume": "12", "Issue": "1", "PubDate": {"Year": "2022", "Month": "Sep", "Day": "06"}}, "Title": "Scientific reports", "ISOAbbreviation": "Sci Rep"}, "ArticleTitle": "Alternative stopping rules to limit tree expansion for random forest models.", "Pagination": {"StartPage": "15113", "MedlinePgn": "15113"}, "Abstract": {"AbstractText": ["Random forests are a popular type of machine learning model, which are relatively robust to overfitting, unlike some other machine learning models, and adequately capture non-linear relationships between an outcome of interest and multiple independent variables. There are relatively few adjustable hyperparameters in the standard random forest models, among them the minimum size of the terminal nodes on each tree. The usual stopping rule, as proposed by Breiman, stops tree expansion by limiting the size of the parent nodes, so that a node cannot be split if it has less than a specified number of observations. Recently an alternative stopping criterion has been proposed, stopping tree expansion so that all terminal nodes have at least a\u00a0minimum number of observations. The present paper proposes three generalisations of this idea, limiting the growth in regression random forests, based on the variance, range, or inter-centile range. The new approaches are applied to diabetes data obtained from the National Health and Nutrition Examination Survey and four other datasets (Tasmanian Abalone data, Boston Housing crime rate data, Los Angeles ozone concentration data, MIT servo data). Empirical analysis presented herein demonstrate that the new stopping rules yield competitive mean square prediction error to standard random forest models. In general, use of the intercentile range statistic to control tree expansion yields much less variation in mean square prediction error, and mean square prediction error is\u00a0also closer to the optimal. The Fortran code developed is provided in the Supplementary Material."], "CopyrightInformation": "\u00a9 2022. This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply."}, "AuthorList": [{"Identifier": [], "AffiliationInfo": [{"Identifier": [], "Affiliation": "Radiation Epidemiology Branch, National Cancer Institute, Bethesda, MD, 20892-9778, USA. mark.little@nih.gov."}, {"Identifier": [], "Affiliation": "Radiation Epidemiology Branch, Division of Cancer Epidemiology and Genetics, Department of Health and Human Services, National Cancer Institute, National Institutes of Health, 9609 Medical Center Drive, Bethesda, MD, 20892-9778, USA. mark.little@nih.gov."}], "LastName": "Little", "ForeName": "Mark P", "Initials": "MP"}, {"Identifier": [], "AffiliationInfo": [{"Identifier": [], "Affiliation": "Biostatistics Branch, National Cancer Institute, Bethesda, MD, 20892-9778, USA."}], "LastName": "Rosenberg", "ForeName": "Philip S", "Initials": "PS"}, {"Identifier": [], "AffiliationInfo": [{"Identifier": [], "Affiliation": "Integrative Data Analytics Program, Center for Data, Mathematical &amp; Computational Sciences, Goucher College, Baltimore, MD, USA."}], "LastName": "Arsham", "ForeName": "Aryana", "Initials": "A"}], "GrantList": [{"GrantID": "Intramural Research Program", "Acronym": "CA", "Agency": "NCI NIH HHS", "Country": "United States"}], "PublicationTypeList": ["Journal Article", "Research Support, N.I.H., Extramural", "Research Support, N.I.H., Intramural"]}, "MedlineJournalInfo": {"Country": "England", "MedlineTA": "Sci Rep", "NlmUniqueID": "101563288", "ISSNLinking": "2045-2322"}, "MeshHeadingList": [{"QualifierName": [], "DescriptorName": "Boston"}, {"QualifierName": [], "DescriptorName": "Los Angeles"}, {"QualifierName": [], "DescriptorName": "Machine Learning"}, {"QualifierName": [], "DescriptorName": "Nutrition Surveys"}], "CoiStatement": "The authors declare no competing interests."}, "PubmedData": {"ReferenceList": [{"Reference": [{"Citation": "Breiman L. Bagging predictors. Mach. Learn. 1996;24:123\u2013140. doi: 10.1007/bf00058655.", "ArticleIdList": ["10.1007/bf00058655"]}, {"Citation": "Breiman L. Random forests. Mach. Learn. 2001;45:5\u201332. doi: 10.1023/a:1010933404324.", "ArticleIdList": ["10.1023/a:1010933404324"]}, {"Citation": "Arsham A, Rosenberg P, Little M. Effects of stopping criterion on the growth of trees in regression random forests. New Engl. J. Stat. Data Sci. 2022 doi: 10.51387/22-NEJSDS5.", "ArticleIdList": ["10.51387/22-NEJSDS5"]}, {"Citation": "randomForest: Breiman and Cutler's Random Forests for Classification and Regression. Version 4.6-14 (CRAN\u2014The Comprehensive R Archive Network, 2018)."}, {"Citation": "ranger. Version 0.12.1 (CRAN\u2014The Comprehensive R Archive Network, 2020)."}, {"Citation": "Probst P, Boulesteix A-L, Bischl B. Tunability: Importance of hyperparameters of machine learning algorithms. J. Mach. Learn. Res. 2019;20:1\u201332."}, {"Citation": "Probst P, Wright MN, Boulesteix A-L. Hyperparameters and tuning strategies for random forest. WIREs Data Mining Knowl. Discov. 2019;9:e1301. doi: 10.1002/widm.1301.", "ArticleIdList": ["10.1002/widm.1301"]}, {"Citation": "randomForestSRC. Version 2.9.3 (CRAN\u2014The Comprehensive R Archive Network, 2020)."}, {"Citation": "partykit. Version 1.2-15 (CRAN\u2014The Comprehensive R Archive Network, 2021)."}, {"Citation": "Hothorn T, Zeileis A. partykit: A modular toolkit for recursive partytioning in R. J. Mach. Learn. Res. 2015;16:3905\u20133909."}, {"Citation": "Meinshausen N. Quantile regression forests. J. Mach. Learn. Res. 2006;7:983\u2013999."}, {"Citation": "Garge NR, Bobashev G, Eggleston B. Random forest methodology for model-based recursive partitioning: The mobForest package for R. BMC Bioinform. 2013;14:125. doi: 10.1186/1471-2105-14-125.", "ArticleIdList": ["10.1186/1471-2105-14-125", "PMC3626834", "23577585"]}, {"Citation": "Seibold H, Zeileis A, Hothorn T. Model-based recursive partitioning for subgroup analyses. Int. J. Biostat. 2016;12:45\u201363. doi: 10.1515/ijb-2015-0032.", "ArticleIdList": ["10.1515/ijb-2015-0032", "27227717"]}, {"Citation": "model4you. Version 0.9-7 (CRAN\u2014The Comprehensive R Archive Network, 2020)."}, {"Citation": "Segal MR, Xiao Y. Multivariate random forests. Wiley Interdiscipl. Rev. Data Mining Knowl. Discov. 2011;1:80\u201387. doi: 10.1002/widm.12.", "ArticleIdList": ["10.1002/widm.12"]}, {"Citation": "MultivariateRandomForest. Version 1.1.5 (CRAN\u2014The Comprehensive R Archive Network, 2017)."}, {"Citation": "Wager S, Athey S. Estimation and inference of heterogeneous treatment effects using random forests. J. Am. Stat. Assoc. 2018;113:1228\u20131242. doi: 10.1080/01621459.2017.1319839.", "ArticleIdList": ["10.1080/01621459.2017.1319839"]}, {"Citation": "Foster JC, Taylor JM, Ruberg SJ. Subgroup identification from randomized clinical trial data. Stat. Med. 2011;30:2867\u20132880. doi: 10.1002/sim.4322.", "ArticleIdList": ["10.1002/sim.4322", "PMC3880775", "21815180"]}, {"Citation": "Li J, et al. A multicenter random forest model for effective prognosis prediction in collaborative clinical research network. Artif. Intell. Med. 2020;103:101814. doi: 10.1016/j.artmed.2020.101814.", "ArticleIdList": ["10.1016/j.artmed.2020.101814", "32143809"]}, {"Citation": "Speiser JL, et al. BiMM forest: A random forest method for modeling clustered and longitudinal binary outcomes. Chemometr. Intell. Lab. Syst. 2019;185:122\u2013134. doi: 10.1016/j.chemolab.2019.01.002.", "ArticleIdList": ["10.1016/j.chemolab.2019.01.002", "PMC6813794", "31656362"]}, {"Citation": "Quadrianto N, Ghahramani Z. A very simple safe-Bayesian random forest. IEEE Trans. Pattern Anal. Mach. Intell. 2015;37:1297\u20131303. doi: 10.1109/TPAMI.2014.2362751.", "ArticleIdList": ["10.1109/TPAMI.2014.2362751", "26357350"]}, {"Citation": "Ishwaran H, Kogalur UB, Blackstone EH, Lauer MS. Random survival forests. Ann. Appl. Stat. 2008;2:841\u2013860. doi: 10.1214/08-AOAS169.", "ArticleIdList": ["10.1214/08-AOAS169"]}, {"Citation": "D\u00edaz-Uriarte R, Alvarez de Andr\u00e9s S. Gene selection and classification of microarray data using random forest. BMC Bioinform. 2006;7:3. doi: 10.1186/1471-2105-7-3.", "ArticleIdList": ["10.1186/1471-2105-7-3", "PMC1363357", "16398926"]}, {"Citation": "Diaz-Uriarte R. GeneSrF and varSelRF: A web-based tool and R package for gene selection and classification using random forest. BMC Bioinform. 2007;8:328. doi: 10.1186/1471-2105-8-328.", "ArticleIdList": ["10.1186/1471-2105-8-328", "PMC2034606", "17767709"]}, {"Citation": "van Lissa, C. J. metaforest: Exploring Heterogeneity in Meta-analysis Using Random Forests. R Package Version 0.1.3. https://CRAN.R-project.org/package=metaforest (2020). Accessed August 2022."}, {"Citation": "Georganos S, et al. Geographical random forests: A spatial extension of the random forest algorithm to address spatial heterogeneity in remote sensing and population modelling. Geocarto Int. 2021;36:121\u2013136. doi: 10.1080/10106049.2019.1595177.", "ArticleIdList": ["10.1080/10106049.2019.1595177"]}, {"Citation": "Zhang G, Lu Y. Bias-corrected random forests in regression. J. Appl. Stat. 2012;39:151\u2013160. doi: 10.1080/02664763.2011.578621.", "ArticleIdList": ["10.1080/02664763.2011.578621"]}, {"Citation": "Song J. Bias corrections for random forest in regression using residual rotation. J. Korean Stat. Soc. 2015;44:321\u2013326. doi: 10.1016/j.jkss.2015.01.003.", "ArticleIdList": ["10.1016/j.jkss.2015.01.003"]}, {"Citation": "Hastie T, Tibshirani R, Friedman J. The Elements of Statistical Learning. Data Mining, Inference, and Prediction. 2. Springer; 2017. pp. 1\u2013745+i-xxii."}], "ReferenceList": []}], "History": [{"Year": "2022", "Month": "3", "Day": "7"}, {"Year": "2022", "Month": "8", "Day": "26"}, {"Year": "2022", "Month": "9", "Day": "6", "Hour": "23", "Minute": "20"}, {"Year": "2022", "Month": "9", "Day": "7", "Hour": "6", "Minute": "0"}, {"Year": "2022", "Month": "9", "Day": "9", "Hour": "6", "Minute": "0"}, {"Year": "2022", "Month": "9", "Day": "6"}], "PublicationStatus": "epublish", "ArticleIdList": ["36068261", "PMC9448733", "10.1038/s41598-022-19281-7", "10.1038/s41598-022-19281-7"]}}], "PubmedBookArticle": []}